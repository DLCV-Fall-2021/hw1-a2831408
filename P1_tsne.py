# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xECmpb794GhpQxbXVa2gPU3sPs7z0J21
"""

! wget -O mymodel.pth https://www.dropbox.com/s/re8kzwmr9sklno5/mymodel.pth?dl=1
!gdown --id '1CIvfO8rDMq5-3vmi0c6mrhDfzqrAZDem' --output hw1_data.zip
! unzip hw1_data.zip

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms
import torchvision.models as models
from torch.utils.data import Dataset, DataLoader
import glob
import os
import numpy as np
from PIL import Image
import torchvision.models as models
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE

class VGG(Dataset):
  def __init__(self, root, transform=None):
    """ Intialize the VGG dataset """
    self.images = None
    self.labels = None
    self.filenames = []
    self.root = root
    self.transform = transform

    # read filenames
    filenames = glob.glob(os.path.join(root, '*.png'))
    for fn in filenames:
      file = fn.split('/')
      file = file[-1]
      label = file.split('_')
      label = int(label[0])
      self.filenames.append((fn, label)) # (file, label) pair
                
    self.len = len(self.filenames)
                              
  def __getitem__(self, index):
    """ Get a sample from the dataset """
    image_fn, label = self.filenames[index]
    image = Image.open(image_fn)
            
    if self.transform is not None:
      image = self.transform(image)

    return image, label

  def __len__(self):
    """ Total number of samples in the dataset """
    return self.len

transformdata = {
  'train': transforms.Compose([
  transforms.Resize((224,224)),
  transforms.RandomHorizontalFlip(),
  transforms.ToTensor(),
  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]),
  'val': transforms.Compose([
  transforms.Resize((224,224)),
  transforms.ToTensor(),
  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]),
}

testset = VGG(root='p1_data/val_50', transform=transformdata['val'])
testset_loader = DataLoader(testset, batch_size=50, shuffle=False, num_workers=1)

use_cuda = torch.cuda.is_available()
device = torch.device("cuda" if use_cuda else "cpu")
device

model = models.vgg16_bn()
model.classifier._modules['6'] = nn.Linear(4096, 50)
model.to(device)
model.load_state_dict(torch.load('mymodel.pth', map_location=device))
model.classifier._modules.pop('6')
model.classifier._modules.pop('5')
model.classifier._modules.pop('4')
model

with torch.no_grad():
    feature = np.zeros((0,4096))
    label = np.zeros(0,dtype=np.int32)
    for data, target in testset_loader:
        label = np.concatenate((label, target.cpu().numpy()), axis=0)
        data = data.to(device)
        output = model(data)
        output = output.cpu().numpy()
        feature = np.concatenate((feature, output), axis=0)

feature_tsne = TSNE(n_components=2, init='random', random_state=5, verbose=1).fit_transform(feature)

f_min, f_max = feature_tsne.min(0), feature_tsne.max(0)
feature_norm = (feature_tsne - f_min) / (f_max - f_min)
plt.figure(figsize=(10, 10))
for i in range(feature_norm.shape[0]):
    plt.scatter(feature_norm[i,0], feature_norm[i,1], color=(label[i]/50,label[i]%20/20,label[i]%10/10))
plt.xticks([])
plt.yticks([])
plt.show()